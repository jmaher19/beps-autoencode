{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ensure python 3 compatibility\n",
    "from __future__ import division, print_function, absolute_import\n",
    "\n",
    "# Import necessary libraries:\n",
    "# General utilities:\n",
    "import sys\n",
    "import os\n",
    "import math\n",
    "\n",
    "# Computation:\n",
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "# Visualization:\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "# Finally, pycroscopy itself\n",
    "import pycroscopy as px\n",
    "\n",
    "from os.path import join as pjoin\n",
    "\n",
    "# set up notebook to show plots within the notebook\n",
    "% matplotlib inline\n",
    "\n",
    "import glob\n",
    "\n",
    "#import moviepy.video.io.ImageSequenceClip\n",
    "#try:\n",
    "#    output = subprocess.check_output(['ffmpeg', '-version'])\n",
    "#    version = output.split(b'\\n')[0].split()[2]\n",
    "#    print('Found: ffmpeg v{}'.format(version.decode('utf-8')))\n",
    "#    ffmpeg_installed = True\n",
    "#except:\n",
    " #   ffmpeg_installed = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%file custom.mplstyle\n",
    "\n",
    "axes.linewidth: 1.5\n",
    "xtick.major.size: 6\n",
    "xtick.minor.size: 2\n",
    "xtick.major.width: 1.5\n",
    "xtick.minor.width: 1.5\n",
    "ytick.major.size: 6\n",
    "ytick.minor.size: 2\n",
    "ytick.major.width: 1.5\n",
    "ytick.minor.width: 1.5\n",
    "axes.labelweight: bold\n",
    "axes.labelpad: 1\n",
    "axes.labelsize: 12\n",
    "xtick.major.pad: 1\n",
    "ytick.major.pad: 1\n",
    "xtick.labelsize: 12\n",
    "ytick.labelsize: 12\n",
    "xtick.top: True\n",
    "ytick.right: True\n",
    "xtick.direction: in\n",
    "ytick.direction: in\n",
    "image.interpolation: nearest\n",
    "    \n",
    "# Loads the custom style\n",
    "plt.style.use('./custom.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use('./custom.mplstyle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " input_file_path ='D:/PZT001_BEPs_0003.h5' #px.io_utils.uiGetFile(caption='Select translated .h5 file or raw experiment data',\n",
    "                                         #filter='Translated file (*.h5);; \\\\ Parameters for raw BE data (*.txt *.mat *xls *.xlsx)')\n",
    "\n",
    "(data_dir, data_name) = os.path.split(input_file_path)\n",
    "\n",
    "if input_file_path.endswith('.h5'):\n",
    "    # No translation here\n",
    "    h5_path = input_file_path\n",
    "    tl = px.LabViewH5Patcher()\n",
    "    hdf = tl.translate(h5_path)\n",
    "else:\n",
    "    # Set the data to be translated\n",
    "    data_path = input_file_path\n",
    "\n",
    "    (junk, base_name) = os.path.split(data_dir)\n",
    "\n",
    "    # Check if the data is in the new or old format.  Initialize the correct translator for the format.\n",
    "    if base_name == 'newdataformat':\n",
    "        (junk, base_name) = os.path.split(junk)\n",
    "        translator = px.BEPSndfTranslator(max_mem_mb=max_mem)\n",
    "    else:\n",
    "        translator = px.BEodfTranslator(max_mem_mb=max_mem)\n",
    "    if base_name.endswith('_d'):\n",
    "        base_name = base_name[:-2]\n",
    "    # Translate the data\n",
    "    h5_path = translator.translate(data_path, show_plots=True, save_plots=False)\n",
    "    tl = px.LabViewH5Patcher()\n",
    "    hdf = tl.translate(h5_path)\n",
    "print('Working on:\\n' + h5_path)\n",
    "\n",
    "h5_main = px.hdf_utils.getDataSet(hdf.file, 'Raw_Data')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_sho_group = px.hdf_utils.findH5group(h5_main, 'SHO_Fit')\n",
    "sho_fitter = px.BESHOmodel(h5_main, parallel=True)\n",
    "if len(h5_sho_group) == 0:\n",
    "    print('No SHO fit found. Doing SHO Fitting now')\n",
    "    h5_sho_guess = sho_fitter.do_guess(strategy='complex_gaussian', processors=max_cores)\n",
    "    h5_sho_fit = sho_fitter.do_fit(processors=max_cores)\n",
    "else:\n",
    "    print('Taking previous SHO results already present in file')\n",
    "    h5_sho_guess = h5_sho_group[-1]['Guess']\n",
    "    try:\n",
    "        h5_sho_fit = h5_sho_group[-1]['Fit']\n",
    "    except KeyError:\n",
    "        print('Previously computed guess found. Now computing fit')\n",
    "        h5_sho_fit = sho_fitter.do_fit(processors=max_cores, h5_guess=h5_sho_guess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify output file path\n",
    "#output_file_path = './'\n",
    "\n",
    "# If HV amplifier was used set high_voltage_amplf to 10, else to 1\n",
    "#high_voltage_amplf = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(Nd_mat, success) = px.io.hdf_utils.reshape_to_Ndims(h5_sho_fit)\n",
    "print('Reshape Success = ' + str(success))\n",
    "print('Nd_mat shape = ', Nd_mat.shape)\n",
    "\n",
    "phase_offset = Nd_mat[0, 0, 1, 0, 0]['Phase [rad]']\n",
    "\n",
    "# phase_offset = 0;\n",
    "\n",
    "print('Phase offset [rad] = ', phase_offset)\n",
    "\n",
    "Nd_mat[:,:,:,:,:]['Phase [rad]'] = Nd_mat[:,:,:,:,:]['Phase [rad]'] - phase_offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Nd_mat[\"Phase [rad]\"].shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'\n",
    "\n",
    "from scipy import io\n",
    "import numpy as np\n",
    "import pycroscopy as px\n",
    "import matplotlib.pyplot as plt\n",
    "from os.path import join as pjoin\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import keras\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import (Dense, Conv1D, Convolution2D, GRU, LSTM, Recurrent, Bidirectional, TimeDistributed,\n",
    "                          Dropout, Flatten, RepeatVector, Reshape, MaxPooling1D, UpSampling1D, BatchNormalization)\n",
    "from keras.layers.core import Lambda\n",
    "from keras.optimizers import Adam\n",
    "import os\n",
    "from os.path import join as pjoin\n",
    "from keras.regularizers import l1\n",
    "import sys\n",
    "\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#len(qf_on.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def norm(indat):\n",
    "    indat-=np.mean(indat)\n",
    "    indat/=np.std(indat)\n",
    "    return indat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amp_off = np.atleast_3d(Nd_mat[\"Amplitude [V]\"][:,:,:,1,2].reshape(-1,128))\n",
    "phase_off = np.atleast_3d(Nd_mat[\"Phase [rad]\"][:,:,:,1,2].reshape(-1,128))\n",
    "freq_off = np.atleast_3d(Nd_mat[\"Frequency [Hz]\"][:,:,:,1,2].reshape(-1,128))\n",
    "qf_off = np.atleast_3d(Nd_mat[\"Quality Factor\"][:,:,:,1,2].reshape(-1,128))\n",
    "\n",
    "amp_on = np.atleast_3d(Nd_mat[\"Amplitude [V]\"][:,:,:,0,2].reshape(-1,128))\n",
    "phase_on = np.atleast_3d(Nd_mat[\"Phase [rad]\"][:,:,:,0,2].reshape(-1,128))\n",
    "freq_on = np.atleast_3d(Nd_mat[\"Frequency [Hz]\"][:,:,:,0,2].reshape(-1,128))\n",
    "qf_on= np.atleast_3d(Nd_mat[\"Quality Factor\"][:,:,:,0,2].reshape(-1,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "amp_off = np.atleast_3d(norm(amp_off))\n",
    "phase_off = np.atleast_3d(norm(phase_off))\n",
    "freq_off = np.atleast_3d(norm(freq_off))\n",
    "qf_off = np.atleast_3d(norm(qf_off))\n",
    "\n",
    "amp_on = np.atleast_3d(norm(amp_on))\n",
    "phase_on = np.atleast_3d(norm(phase_on))\n",
    "freq_on = np.atleast_3d(norm(freq_on))\n",
    "qf_on= np.atleast_3d(norm(qf_on))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(len(qf_on.reshape(-1))):\n",
    "    if qf_on.reshape(-1)[i] > 900:\n",
    "        qf_on.reshape(-1)[i] = np.mean(qf_on)\n",
    "        \n",
    "for i in range(len(qf_off.reshape(-1))):\n",
    "    if qf_off.reshape(-1)[i] > 900:\n",
    "        qf_off.reshape(-1)[i] = np.mean(qf_off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#np.std((Nd_mat[\"Amplitude [V]\"][:,:,:,1,2].reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(24, 18))\n",
    "ax_amp_off = plt.subplot2grid((2, 4), (0, 0), colspan=1, rowspan=1)\n",
    "ax_amp_on = plt.subplot2grid((2, 4), (0, 1), colspan=1, rowspan=1)\n",
    "ax_phase_off = plt.subplot2grid((2, 4), (0, 2), colspan=1, rowspan=1)\n",
    "ax_phase_on = plt.subplot2grid((2, 4), (0, 3), colspan=1, rowspan=1)\n",
    "ax_freq_off = plt.subplot2grid((2, 4), (1, 0), colspan=1, rowspan=1)\n",
    "ax_freq_on = plt.subplot2grid((2, 4), (1, 1), colspan=1, rowspan=1)\n",
    "ax_qf_off = plt.subplot2grid((2, 4), (1, 2), colspan=1, rowspan=1)\n",
    "ax_qf_on = plt.subplot2grid((2, 4), (1, 3), colspan=1, rowspan=1)\n",
    "\n",
    "\n",
    "ax_amp_off.hist(amp_off.reshape(-1),100)\n",
    "ax_amp_on.hist(amp_on.reshape(-1),100)\n",
    "ax_phase_off.hist(phase_off.reshape(-1),100)\n",
    "ax_phase_on.hist(phase_on.reshape(-1),100)\n",
    "ax_freq_off.hist(freq_off.reshape(-1),100) \n",
    "ax_freq_on.hist(freq_on.reshape(-1),100)\n",
    "ax_qf_off.hist(qf_off.reshape(-1),100)\n",
    "ax_qf_on.hist(qf_on.reshape(-1),100)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#(amp_on.reshape(-1),100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## PCA of imput data to remove noise\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "am = amp_off[:,:,0]\n",
    "am.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set the number of principle components\n",
    "PC_number = 70\n",
    "pca = sklearn.decomposition.PCA(n_components=PC_number)\n",
    "pca_amp = pca.fit(amp_off[:,:,0])\n",
    "pca_recon_amp = pca.inverse_transform(pca.transform(amp_off[:,:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_input_amp_off = np.atleast_3d(pca_recon_amp[:,::2])\n",
    "pca_input_amp_off.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1,2, figsize=(6,3))\n",
    "\n",
    "axes[0].plot(np.linspace(1, PC_number, PC_number),\n",
    "             np.cumsum(pca_amp.explained_variance_ratio_) * 100,\n",
    "             '-ok')\n",
    "t = np.random.randint(0,3600)\n",
    "axes[1].plot(amp_off[t,:])\n",
    "axes[1].plot(pca_recon_amp[t,:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_folder(folder_name, root='./'):\n",
    "\n",
    "    folder = pjoin(root, '{}'.format(folder_name))\n",
    "    os.makedirs(folder, exist_ok=True)\n",
    "\n",
    "    return (folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network1(inp):\n",
    "    out = Bidirectional(LSTM(128, return_sequences=False))(inp)\n",
    "    en_out_a_off = Dense(16, activation='relu')(out)\n",
    "    x = RepeatVector(64)(en_out_a_off)   \n",
    "    #x = TimeDistributed(Dense(1, activation='linear'))(en_out_a_off)\n",
    "    x = Bidirectional(LSTM(128, activation= \"sigmoid\", return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(1, activation='linear'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network2(inp):\n",
    "    out = Bidirectional(LSTM(128, return_sequences=True))(inp)\n",
    "    en_out_a_off = Dense(16, activation='relu')(out)\n",
    "    #x = RepeatVector(64)(en_out_a_off)   \n",
    "    #x = TimeDistributed(Dense(1, activation='linear'))(en_out_a_off)\n",
    "    x = Bidirectional(LSTM(128, activation= \"sigmoid\", return_sequences=True))(en_out_a_off)\n",
    "    x = TimeDistributed(Dense(1, activation='linear'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def network3(inp):\n",
    "    out = Bidirectional(LSTM(128,activation = \"sigmoid\", return_sequences=True))(inp)\n",
    "    x = TimeDistributed(Dense(1, activation=\"linear\"))(out)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def encode_layer(size, numbernodes,x):\n",
    "    for i in range(size-1):\n",
    "        x = Bidirectional(LSTM(numbernodes, return_sequences=True))(x)\n",
    "    out = Bidirectional(LSTM(numbernodes, return_sequences=False))(x)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def decode_layer(size, numbernodes,x):\n",
    "    x = RepeatVector(64)(x)\n",
    "    for i in range(size):\n",
    "        x = Bidirectional(LSTM(numbernodes, return_sequences=True))(x)\n",
    "    x = TimeDistributed(Dense(1, activation='relu'))(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mods = keras.models.load_model(\"D:/Layerwise/amp_only4/weights.4419-0.02.hdf5\")\n",
    "mods_2 = keras.models.load_model(\"D:/Layerwise/amp_second/weights.5000-0.02.hdf5\")\n",
    "mods_3 = keras.models.load_model(\"D:/Layerwise/amp_third/weights.5000-0.02.hdf5\")\n",
    "mods_4 = keras.models.load_model(\"D:/Layerwise/amp_encode/weights.5000-0.01.hdf5\")\n",
    "mods_5 = keras.models.load_model(\"D:/Layerwise/amp_decode_2/weights.5000-0.01.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mods_5.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_off_freq=Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2]//2,1))\n",
    "x = network2(input_off_freq)\n",
    "gen = Model(inputs=[input_off_freq], \n",
    "              outputs=x)\n",
    "\n",
    "gen.compile(optimizer=Adam(3e-5),loss='mse')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbs_list = mods.get_weights()\n",
    "gen.set_weights(lbs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_ith_layer_output(model, X, i, mode='test'):\n",
    "    ''' see https://keras.io/getting-started/faq/#keras-faq-frequently-asked-keras-questions'''\n",
    "    get_ith_layer = keras.backend.function(\n",
    "        [model.layers[0].input, keras.backend.learning_phase()], [model.layers[i].output])\n",
    "    layer_output = get_ith_layer([X, 0 if mode=='test' else 1])[0]\n",
    "    return layer_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = get_ith_layer_output(gen,pca_input_amp_off,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer_1=Input(shape=(one.shape[1:]))\n",
    "x = network2(input_layer_1)\n",
    "gen_2 = Model(inputs=[input_layer_1], \n",
    "              outputs=x)\n",
    "\n",
    "gen_2.compile(optimizer=Adam(3e-5),loss='mse')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbs_2 = mods_2.get_weights()\n",
    "gen_2.set_weights(lbs_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "two = get_ith_layer_output(gen_2,one,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_layer_1=Input(shape=(two.shape[1:]))\n",
    "x = network1(input_layer_1)\n",
    "model = Model(inputs=[input_layer_1], \n",
    "              outputs=x)\n",
    "model.compile(optimizer=Adam(3e-5),loss='mse')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbs_3 = mods_3.get_weights()\n",
    "model.set_weights(lbs_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the ith layer\n",
    "three = get_ith_layer_output(model, two, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "three.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# create final layer with ith layer input\n",
    "\n",
    "input_decode=Input(shape=(three.shape[1:]))\n",
    "x = network3(input_decode)\n",
    "decode = Model(inputs=[input_decode],\n",
    "              outputs=x)\n",
    "decode.compile(optimizer=Adam(3e-5),loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbs_4 = mods_4.get_weights()\n",
    "decode.set_weights(lbs_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "four = get_ith_layer_output(decode, three, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "input_decode=Input(shape=(four.shape[1:]))\n",
    "x = network3(input_decode)\n",
    "decode_2 = Model(inputs=[input_decode],\n",
    "              outputs=x)\n",
    "decode_2.compile(optimizer=Adam(3e-5),loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_off_amp =Input(shape=(Nd_mat[\"Phase [rad]\"].shape[2]//2,1))\n",
    "\n",
    "amp = encode_layer(3,128, input_off_amp)\n",
    "amp = Dense(8, activation='relu',activity_regularizer=l1(10e-4))(amp)\n",
    "\n",
    "de_amp = decode_layer(3,128,amp)\n",
    "\n",
    "one_channel= Model(inputs=[input_off_amp],\n",
    "                  outputs=de_amp)\n",
    "one_channel.compile(optimizer=Adam(3e-5), loss=\"mse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "first = mods.layers[1].get_weights()\n",
    "second = mods_2.layers[1].get_weights()\n",
    "third = mods_3.layers[1].get_weights()\n",
    "dense_w = mods_3.layers[2].get_weights()\n",
    "fourth = mods_3.layers[4].get_weights()\n",
    "fith = mods_4.layers[1].get_weights()\n",
    "sixth = mods_5.layers[1].get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one_channel.layers[1].set_weights(first)\n",
    "one_channel.layers[2].set_weights(second)\n",
    "one_channel.layers[3].set_weights(third)\n",
    "one_channel.layers[4].set_weights(dense_w)\n",
    "one_channel.layers[6].set_weights(fourth)\n",
    "one_channel.layers[7].set_weights(fith)\n",
    "one_channel.layers[8].set_weights(sixth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mods = keras.models.load_model(\"C:/Users/Josh_/CKPFM_Doped_001_PZT/amp_no_pretrain/weights.2300-0.58.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lbs = mods.get_weights()\n",
    "one_channel.set_weights(lbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_channel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path = 'amp_pretrain'\n",
    "make_folder(Path)\n",
    "tbCallBack = keras.callbacks.TensorBoard(\n",
    "    log_dir='./' + Path, histogram_freq=0, write_graph=True, write_images=True)\n",
    "filepath = './' + Path + '/weights.{epoch:02d}-{val_loss:.2f}.hdf5'\n",
    "checkpoint = keras.callbacks.ModelCheckpoint(filepath, verbose=0, save_best_only=False,\n",
    "                                             save_weights_only=False, mode='min', period=1)\n",
    "#from keras.utils import multi_gpu_model\n",
    "\n",
    "# Replicates `model` on 2 GPUs.\n",
    "# This assumes that your machine has 2 available GPUs.\n",
    "#parallel_model = multi_gpu_model(model, gpus=2)\n",
    "#parallel_model.compile(optimizer=Adam(3e-5),loss='mse')\n",
    "\n",
    "one_channel.fit([pca_input_amp_off], \n",
    "            [pca_input_amp_off],\n",
    "          validation_data=([pca_input_amp_off], \n",
    "          [pca_input_amp_off]),\n",
    "          epochs=5000,batch_size=768, callbacks=[tbCallBack, checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
